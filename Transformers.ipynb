{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeIztQ8c90Nt/U7w69dhwi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sra1panasa/NLP/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers:\n",
        "blogs must visit:\n",
        "\n",
        "\n",
        "Bert USe case : https://www.kaggle.com/code/harshjain123/bert-for-everyone-tutorial-implementation\n",
        "\n",
        "https://dev.to/meetkern/gpt-and-bert-a-comparison-of-transformer-architectures-2k46\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2019/06/understanding-transformers-nlp-state-of-the-art-models/\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2021/06/why-and-how-to-use-bert-for-nlp-text-classification/\n",
        "\n",
        "He has explained very clearely == He mentioned as The** New Sensation in NLP**: Googleâ€™s BERT (Bidirectional Encoder Representations from Transformers)"
      ],
      "metadata": {
        "id": "kJfvUKprRRly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "finalized transformer blogs:\n",
        "\n",
        "https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0\n",
        "\n",
        "https://www.datacamp.com/tutorial/an-introduction-to-using-transformers-and-hugging-face?utm_source=google&utm_medium=paid_search&utm_campaignid=19863514238&utm_adgroupid=147433231419&utm_device=c&utm_keyword=&utm_matchtype=&utm_network=g&utm_adpostion=&utm_creative=652967469727&utm_targetid=dsa-1947282172981&utm_loc_interest_ms=&utm_loc_physical_ms=9062142&utm_content=dsa~page~community-tuto&utm_campaign=230119_1-sea~dsa~tutorials_2-b2c_3-in_4-prc_5-na_6-na_7-le_8-pdsh-go_9-na_10-na_11-na&gclid=Cj0KCQjwlumhBhClARIsABO6p-x4S6JIp9RIOrTfCwnuFBwsSAvQnTgFUVtzH1MStGL4MeiWMP7ZNUYaAoXCEALw_wcB\n",
        "\n",
        "https://machinelearningmastery.com/the-transformer-model/\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2019/06/understanding-transformers-nlp-state-of-the-art-models/"
      ],
      "metadata": {
        "id": "H1DLHFr9R_0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KvM5GydMByiT"
      }
    }
  ]
}